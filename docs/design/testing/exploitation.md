# Test procedures for the exploitation system

---

ðŸš§ **TODO TODO_PL** : compile test procedures for Exploitation ðŸš§

---

## Testing approach

Throughout the development process, various testing methodologies are applied as
appropriate to the relevant development stage.

### Requirements and use cases approach

[Describe how use cases are defined]

The user stories will drive the initial development of the AVL as they define
the capabilities to be implemented. They will be defined in detail in Task 3
with the respective scientific experts but must be translated into specific work
items by the product owners, which is done within this task. While the Statement
of Work suggests that Champion Users may be the product owners in Scrum
terminology, we suggest this critical role to be taken by a member of the
consortium to ensure the required commitment for a successful and efficient
development process.

The product owner fully understands the use case to be implemented in remains in
close contact with the champion users, which may be external or internal to AVL,
and creates and maintains the product backlog, which is a pile of work items. 

### Software development approach

[Describe how requirements are derived from use cases]

At the beginning of each iteration cycle in the development process, the product
owner prioritizes the items in the backlog of the use case and decides with the
champion users and the team on the items to be implemented in the next sprint.
The product owner hence interacts closely and frequently with the development
team as well as the scientific users. It is thus essential that this person
understands in detail both sides and is also able to communicate with
researchers from agricultural sciences and with software developers and cloud
engineers. Each iteration of the AVL system in phase 1 will add features to the
system that further implement at least one of the use cases. Deliverable item
D2.1, User Stories, is thus a workflow in AVL rather than a mere description
that can be fully reproduced, first by the product owner who is the first person
external to the development team to validate any new capability of the system,
but then also the other stakeholders including the champion users.

### Agile test approach

[General description of agile test methodology]

The Agricultural Virtual Laboratory will be implemented following a Scrum software development
approach. It advocates frequent releases in recurring iteration cycles, so called sprints, as requested
by the SoW [AD-1]. The Scrum process foresees clear roles like the Product owner, who compiles
requirements in the so-called backlog and prioritizes them, the Scrum Master, who manages and
facilitates the software development process in fixed-term sprints and the Team, who develops the
software of service. The fixed length of the sprints leads to frequent releases, which are tested by the
Product owners and other users, stakeholders in Scrum terminology. By this means, it is ensured that
the software under development is continuously evaluated and feedback or even new requirements
can be addressed in the next iteration. Hence, the software co-evolves with the requirements of its
users in an agile manner.

The AVL software development team will engage in stand-up meetings, pair negotiation, unit testing,
pair programming and test-driven development (Figure 17). These techniques and activities have
shown to improve software quality and responsiveness to changing customer requirements.
Pair programming is more than it sounds: two programmers at one computer. One drives; the other
navigates. Switching roles fluidly, they constantly communicate. Together, they accomplish better
work more quickly than either could alone. The driver types, focusing on tactics and writing clean code
that compiles and runs. The navigator focuses on strategy â€“ how the code fits into the overall design
and which tests will drive the code forward.

Test-driven development (TDD) is a technique that alerts the programmer to programming mistakes
moments after she made them â€“ in fact a tool so powerful that it virtually eliminates the need for
debugging. TDD is a rapid cycle of testing, coding, and refactoring. When adding a feature, a pair of
programmers may perform dozens of these cycles, implementing and refining the software in tiny
steps until there is nothing left to add and nothing left to take away. Research indeed has shown that
TDD substantially reduces the incidence of defects. It also helps improving design, documents your
interfaces, and guards against future mistakes.

Acceptance testing allows the Product Owner or other users to validate the
software. The final acceptance tests are performed under supervision of the
Product Owner. Nevertheless, continuous acceptance testing carried out by
quality assurance engineers, is integrated into the software development life
cycle, revealing problems and erroneous developments at an early stage.

## Software verification

[Describe verification tests: automated unit and integration tests. Link to
tests in repository and test results.]

Unit-level testing ensures the correct functionality and validity of individual,
usually relatively small, software units: a procedure or function in a
procedural language, or a class in an object-oriented language. Explicit
dependencies on external interface implementations are avoided by means of
mock-up implementations, resulting in full control of the test environment.
Unit-level tests are defined and carried out by software developers. The primary
input for the definition of unit-level tests is common sense and domain-specific
knowledge, as well as the requirements provided by the Product owner or AVL
users.

Note that as part of the test-driven, incremental software development,
unit-level tests will be defined and coded before a new feature is implemented.
A developer realises a new feature by making its associated unit-level tests run
successfully.

Integration testing ensures that the developed software behaves as expected
within the target environment. Quality testers define integration tests for
which the primary input is the Requirements Baseline. Implicit and informal
integration testing is also carried out by developers while running or debugging
the software within the integrated development environment.

In addition, integration tests run automatically on our build servers.
Rebuilding takes place whenever source code in the source code repository has
been changed. If there is a problem with the build, an email notification is
sent to responsible developers. Integration tests include unit-level tests for
testing individual classes separately (as described above) as well as
higher-level tests for verifying concepts.

Stress tests will be conducted to assess performance in extreme cases like e.g.
reading or processing large data takes. Stress tests will be benchmarked to
provide information to optimization tasks, if necessary.

System tests will be defined and carried out by using the AVL system as
installed by automatically build installer packages.

## Software validation

[Describe validation methodology. Link to data sets used for validation,
use case(s), and results.]

Software verification is the process ensuring that adequate specifications and
inputs exist for all software development activities, and that the outputs of
the activities are correct and consistent with the specifications and the input.
The final outputs of this procedure are verified software modules and updated
Software Version Procedure (SVerP).

Software validation is the process of ensuring that the requirements baseline
functions and performances are correctly and completely implemented in the final
software. The Software Product Assurance (SPA) ensures software validity by
testing on three major levels: unit-level testing, integration testing and
acceptance testing. All problems related to software components will be
documented and followed up in an issue tracker system.
